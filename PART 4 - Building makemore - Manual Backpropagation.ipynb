{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Building makemore (IV) : Manual Backpropagation</h1>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional links :\n",
    "    \n",
    "- [BatchNorm paper](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "- [Besselâ€™s Correction](https://math.oxford.emory.edu/site/math117/besselCorrection/)\n",
    "- [Bengio et al. 2003 MLP LM](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there no change change in the first several cells from last notebook (part IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words : 32033\n",
      "The longest word has 15 charachters\n",
      "The 8 first words are : ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(f\"The total number of words : {len(words)}\")\n",
    "print(f\"The longest word has {max(len(w) for w in words)} charachters\")\n",
    "print(f\"The 8 first words are : {words[:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoder (string to integer) that we're going to work with is :\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "\n",
      "The decoder (integer to string) that we're going to work with is :\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "The vocabulary of size 27 we're working with is :\n",
      "dict_values(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '.'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "# Encoder : convert string to integer\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "print(f\"The encoder (string to integer) that we're going to work with is :\\n{stoi}\\n\")\n",
    "\n",
    "# Decoder : convert integer to string\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(f\"The decoder (integer to string) that we're going to work with is :\\n{itos}\")\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(itos)\n",
    "\n",
    "print(f\"The vocabulary of size {len(itos)} we're working with is :\\n{itos.values()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one? (T : time dimension)\n",
    "\n",
    "def build_dataset(words):\n",
    "    \"\"\"Takes a list of some words and builds the arrays X and Y\n",
    "    for those words only\"\"\"\n",
    "    \n",
    "    X, Y = [], []\n",
    "  \n",
    "    for w in words:\n",
    "        context = [0] * block_size   # initial context is 3 dots '...'\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "    \n",
    "    # convert the lists into toch tensors\n",
    "    X = torch.tensor(X)    # contexts\n",
    "    Y = torch.tensor(Y)    # indexes of the ground truths\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)      # Shuffling the words\n",
    "n1 = int(0.8*len(words))   # length of the training data (80%)\n",
    "n2 = int(0.9*len(words))   # length of validation data (10%), and the remaigning 10% is for testing\n",
    "\n",
    "# Building training, validation and testing datasets\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boilerplate done, now we get to the action :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Backpropagation\n",
    "\n",
    "In PyTorch, when we perform operations that involve gradients, such as backpropagation, the gradients are typically stored in the `.grad` attribute of the tensors involved. This attribute holds the computed gradients, which can then be used for optimization algorithms like gradient descent.\n",
    "\n",
    "To truly understand how backpropagation works, we will write lines of code to calculate the gradient of the loss function with respect to each parameter. We will then use the helper function `cmp()` below to compare the results with Torch's `.grad` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    \"\"\"compares the manually calculated gradients to PyTorch gradients.\n",
    "        s : (string) name of the parameter\n",
    "        dt : calculated gradient\n",
    "        t : parameter\"\"\"\n",
    "    \n",
    "  # dt calculated by us, and t.grad calculated by pytorch\n",
    "    ex = torch.all(dt == t.grad).item()         # verifying if they're equal, 'ex' is boolean\n",
    "    app = torch.allclose(dt, t.grad)            # if note exactly equal, 'app' is boolean\n",
    "    maxdiff = (dt - t.grad).abs().max().item()  # the error between the two, 'maxdiff' is float\n",
    "    print(f\"{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the provided code snippet, `g` is an instance of `torch.Generator` that is used to control the randomness of the generated values. By setting a seed for the generator, we ensure that the random numbers generated by PyTorch are reproducible.\n",
    "\n",
    "Here's a breakdown of the role of `g`:\n",
    "\n",
    "* **torch.Generator :** This class in PyTorch provides functionality for generating random numbers. We can create an instance of `torch.Generator` using various methods.\n",
    "\n",
    "* **manual_seed :** The `.manual_seed()` method sets the seed for the random number generator. By setting the seed to a specific value (in this case, 25101989), we ensure that the sequence of random numbers generated by the generator will be the same every time our code is run with the same seed.\n",
    "\n",
    "* **generator=g :** The generator argument specifies the generator to be used for generating random numbers. By passing the `g` generator instance to the generator argument when calling `torch.randn()`, we ensure that the random numbers generated by `torch.randn()` will be reproducible based on the seed set for `g`.\n",
    "\n",
    "In summary, `g` is used to control the randomness of the generated values by setting a seed for the random number generator. This ensures that the random numbers generated by `torch.randn()` will be consistent and reproducible across different runs of the code, which can be crucial for debugging, testing, and ensuring consistent results in machine learning experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10           # the dimensionality of the character embedding vectors (C : channels dimension)\n",
    "n_hidden = 64         # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(25101989) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd), generator=g)  # embedding table : shape(vocab_size, n_embd)\n",
    "\n",
    "# hidden layers\n",
    "## Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)  # shape(n_embd * block_size, n_hidden)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of BN. shape (n_hidden)\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1  # shape (n_hidden, vocab_size)\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1  # shape (vocab_size)\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0   # shape(1, n_hidden)\n",
    "bnbias = torch.randn((1, n_hidden))*0.1         # shape(1, n_hidden)\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "# (learnable) model parameters :\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "\n",
    "# number of parameters in total\n",
    "print(sum(p.nelement() for p in parameters)) \n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # B, Batch dimension\n",
    "n = batch_size   # a shorter variable also, for convenience\n",
    "\n",
    "# construct a minibatch : sampling 32 random Xtr indeces, and use them to exract 32 random rows from Xtr (batch)\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3]) torch.Size([32]) torch.Size([27, 10])\n"
     ]
    }
   ],
   "source": [
    "print(Xb.shape, Yb.shape, C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1642, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "# I chunkated into multiple steps to make the operation explicit, facilitating the calcul of the gradients\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors ; shape(batch_size, block_size, n_embd)\n",
    "embcat = emb.view(emb.shape[0], -1) # Flatten for each example from the batch, i.e. concatenate the vectors ; shape(batch_size, block_size * n_embd)\n",
    "\n",
    "# Linear layer 1\n",
    "### hprebn shape : (batch_size, block_size * n_embd) @ (block_size * n_embd, n_hidden) + (n_hidden) ----broadcasting---->\n",
    "## (batch_size, n_hidden) + (n_hidden) ---broadcasting--> (batch_size, n_hidden) + (batch_size, n_hidden)----> (batch_size, n_hidden)\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-batch normalization ; shape(batch_size,n_hidden)\n",
    "# BatchNorm (bn) layer\n",
    "## Calculating the mean & variance of each feature (i.e. output of each neurone)\n",
    "### bnmeani shape : (batch_size,n_hidden)---sum(0,keepdim)--->(1,n_hidden)\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)  # shape(1,n_hidden)\n",
    "### bndiff shape :(batch_size,n_hidden)-(1,n_hidden)---broadcasting-->(batch_size,n_hidden)-(batch_size,n_hidden)---->(batch_size,n_hidden)\n",
    "bndiff = hprebn - bnmeani             # (batch_size,n_hidden)           \n",
    "bndiff2 = bndiff**2                         #shape(batch_size,n_hidden)\n",
    "### bnvar shape : (batch_size,n_hidden)---sum(0,keepdim)---->(1,n_hidden)\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # variance; note: Bessel's correction (dividing by n-1, not n) \n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5    # shape(1,n_hidden); epsilon = 1e-5\n",
    "### bnraw shape : (batch_size,n_hidden) * (1,n_hidden)----broadcasting--->(batch_size,n_hidden)*(batch_size,n_hidden)------>(batch_size,n_hidden)\n",
    "bnraw = bndiff * bnvar_inv  # (batch_size,n_hidden)\n",
    "### hpreact shape : (1, n_hidden) * (batch_size,n_hidden) + (1, n_hidden) ---broadcasting---> \n",
    "###(batch_size,n_hidden)*(batch_size,n_hidden) + (1, n_hidden)--- * is element-wise mutlipl--->\n",
    "##(batch_size,n_hidden)+(1, n_hidden)---broadcasting---->(batch_size,n_hidden)+(batch_size,n_hidden)\n",
    "##---->(batch_size,n_hidden) \n",
    "hpreact = bngain * bnraw + bnbias   # (batch_size,n_hidden) \n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer ; shape(batch_size,n_hidden)\n",
    "\n",
    "# Linear layer 2\n",
    "### logits shape : (batch_size,n_hidden) @ (n_hidden, vocab_size) + (vocab_size) ---brodacasting---> (batch_size,vocab_size)\n",
    "logits = h @ W2 + b2 # output layer ; shape(batch_size,vocab_size)\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "### logit_maxes shape : (batch_size,vocab_size)---max(1,keepdim)--->(batch_size,1)\n",
    "logit_maxes = logits.max(1, keepdim=True).values   # shape(batch_size, 1)\n",
    "### norm_logits shape : (batch_size,vocab_size) - (batch_size, 1) ---broadcasting---> (batch_size,vocab_size)\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability # shape(batch_size, vocab_size)\n",
    "counts = norm_logits.exp()   # shape(batch_size, vocab_size)\n",
    "### counts_sum shape : (batch_size, vocab_size)---sum(1,keepdim)--->(batch_size, 1)\n",
    "counts_sum = counts.sum(1, keepdims=True)  # shape(batch_size, 1)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...#shape(batch_size, 1)\n",
    "### probs shape : (batch_size, vocab_size) * (batch_size, 1)---broadcasting---> (batch_size, vocab_size)\n",
    "probs = counts * counts_sum_inv   # shape(batch_size,vocab_size)\n",
    "logprobs = probs.log()            # shape(batch_size,vocab_size)\n",
    "loss = -logprobs[range(n), Yb].mean()  # calculating the mean of -logprobas assigned by the model to the ground truths (n is the batch_size)\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None  # set the grad to zero in Pytorch\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # as far as I know there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of logprobs is : torch.Size([32, 27])\n",
      "\n",
      "The shape of probs is : torch.Size([32, 27])\n",
      "\n",
      "The shape of counts is : torch.Size([32, 27])\n",
      "\n",
      "The shape of counts_sum is : torch.Size([32, 1])\n",
      "\n",
      "The shape of counts_sum_inv is : torch.Size([32, 1])\n",
      "\n",
      "The shape of norm_logits is : torch.Size([32, 27])\n",
      "\n",
      "The shape of logit_maxes is : torch.Size([32, 1])\n",
      "\n",
      "The shape of logits is : torch.Size([32, 27])\n",
      "\n",
      "The shape of bnraw is : torch.Size([32, 64])\n",
      "\n",
      "The shape of bngain is : torch.Size([1, 64])\n",
      "\n",
      "The shape of bnbias is : torch.Size([1, 64])\n",
      "\n",
      "The shape of h is : torch.Size([32, 64])\n",
      "\n",
      "The shape of W2 is : torch.Size([64, 27])\n",
      "\n",
      "The shape of b2 is : torch.Size([27])\n",
      "\n",
      "The shape of hpreact is : torch.Size([32, 64])\n",
      "\n",
      "The shape of bnvar_inv is : torch.Size([1, 64])\n",
      "\n",
      "The shape of bnvar is : torch.Size([1, 64])\n",
      "\n",
      "The shape of bndiff2 is : torch.Size([32, 64])\n",
      "\n",
      "The shape of bndiff is : torch.Size([32, 64])\n",
      "\n",
      "The shape of hprebn is : torch.Size([32, 64])\n",
      "\n",
      "The shape of bnmeani is : torch.Size([1, 64])\n",
      "\n",
      "The shape of embcat is : torch.Size([32, 30])\n",
      "\n",
      "The shape of emb is : torch.Size([32, 3, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in {\"logprobs\" : logprobs, \"probs\":probs, \"counts\":counts, \"counts_sum\":counts_sum, \"counts_sum_inv\":counts_sum_inv, \n",
    "          \"norm_logits\":norm_logits, \"logit_maxes\":logit_maxes, \"logits\":logits, \"bnraw\": bnraw, \"bngain\": bngain, \"bnraw\":bnraw,\n",
    "            \"bnbias\": bnbias, \"h\":h, \"W2\":W2, \"b2\":b2, \"hpreact\":hpreact, \"bnraw\":bnraw,\"bnvar_inv\":bnvar_inv, \"bnvar\":bnvar,\n",
    "            \"bndiff2\":bndiff2, \"bndiff\":bndiff, \"hprebn\":hprebn, \"bnmeani\":bnmeani, \"embcat\":embcat, \"emb\":emb}.items() :\n",
    "    print(f\"The shape of {k} is : {v.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1 \n",
    "\n",
    "We're going to backpropagate through the whol thing **manually**, backpropagating through exactly all the variables as they are defined in the forward pass above, one by one :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# ASTUCES :\n",
    "## each time check the shapes of the parameters involved\n",
    "## broadcasting turns into sum, and sum turns into broadcasting\n",
    "## dX has the same shape as X \n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)    # shape(batch_size,vocab_size)\n",
    "dlogprobs[range(n), Yb] = -1.0/n          # populate dLoss/dlogprobs  \n",
    "dprobs = (1.0 / probs) * dlogprobs        # dLoss/dprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)  # dloss/dcounts_sum_inv\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()   # 1* dnorm_logits\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T   # dloss/dh   # using dimensions of h, W2, and dlogits, and that dZ is the same shape as Z\n",
    "dW2 = h.T @ dlogits   # dloss/dW2   # logits = h @ W2 + b2\n",
    "db2 = dlogits.sum(0)  # dloss/db2\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)   # * is a mulitplication element wise\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0, keepdim=True)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for l in range(Xb.shape[1]):\n",
    "        ix = Xb[k,l]\n",
    "        dC[ix] += demb[k,l]\n",
    "\n",
    "\n",
    "# Verify the results with the grads given by pytorch : \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1642212867736816 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# TASK 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dlogprobs = torch.zeros_like(logprobs)\n",
    "#dlogprobs[range(n), Yb] = -1/n\n",
    "#dprobs = dlogprobs*(1/probs)\n",
    "#dcounts_sum_inv = (dprobs * counts).sum(1, keepdim=True) # from broadcasting to sum\n",
    "#dcounts = dprobs * counts_sum_inv\n",
    "#dcounts_sum = dcounts_sum_inv * (-1/counts_sum**2)\n",
    "#dcounts += torch.ones_like(counts)  # from sum to broadcasting \n",
    "#dnorm_logits = dcounts * counts\n",
    "#dlogits = (dnorm_logits *1).clone()\n",
    "#dlogit_maxes = (dnorm_logits * -1).sum(1, keepdim =True)  # from broadcasting to sum\n",
    "#dlogits += F.one_hot(logits.max(1).indices, num_classes = logits.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1) # computing the softmax along the columns \n",
    "dlogits[range(n), Yb] -=1     # subtructing 1 from the probabilities ossociated with the ground truths\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0383, 0.0822, 0.0419, 0.0236, 0.0293, 0.0323, 0.0391, 0.0579, 0.0490,\n",
       "        0.0429, 0.0158, 0.0207, 0.0671, 0.0418, 0.0635, 0.0523, 0.0240, 0.0271,\n",
       "        0.0206, 0.0445, 0.0248, 0.0324, 0.0240, 0.0162, 0.0406, 0.0219, 0.0260],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0383,  0.0822,  0.0419,  0.0236,  0.0293,  0.0323,  0.0391,  0.0579,\n",
       "         0.0490,  0.0429,  0.0158,  0.0207,  0.0671,  0.0418,  0.0635,  0.0523,\n",
       "         0.0240,  0.0271,  0.0206, -0.9555,  0.0248,  0.0324,  0.0240,  0.0162,\n",
       "         0.0406,  0.0219,  0.0260], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.1910e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22b79032800>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# TASK 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative with regards to its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7974\n",
      "  10000/ 200000: 2.1783\n",
      "  20000/ 200000: 2.3977\n",
      "  30000/ 200000: 2.4808\n",
      "  40000/ 200000: 1.9964\n",
      "  50000/ 200000: 2.3618\n",
      "  60000/ 200000: 2.3317\n",
      "  70000/ 200000: 2.0460\n",
      "  80000/ 200000: 2.3876\n",
      "  90000/ 200000: 2.0786\n",
      " 100000/ 200000: 1.9221\n",
      " 110000/ 200000: 2.3151\n",
      " 120000/ 200000: 2.0362\n",
      " 130000/ 200000: 2.4450\n",
      " 140000/ 200000: 2.3374\n",
      " 150000/ 200000: 2.2713\n",
      " 160000/ 200000: 1.9665\n",
      " 170000/ 200000: 1.8180\n",
      " 180000/ 200000: 2.0376\n",
      " 190000/ 200000: 1.8439\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():  # Telling Pytorch I'm not going to call backward in any of this, letting Pytorch be more efficient \n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation; pre batch norm\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop!\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "        for j in range(Xb.shape[1]):\n",
    "            ix = Xb[k,j]\n",
    "            dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0717408657073975\n",
      "val 2.1080262660980225\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking for the function split_loss\n",
    "def split_loss(split):\n",
    "    \"\"\"claculates the loss in the training, validation, testing\"\"\"\n",
    "    \n",
    "    x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "    }[split]\n",
    "    emb = C[x] # (N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "    h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "    logits = h @ W2 + b2 # (N, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I achieved:\n",
    "# train 2.0717408657073975\n",
    "# val 2.1080262660980225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mona.\n",
      "mayah.\n",
      "see.\n",
      "mad.\n",
      "ryla.\n",
      "reivan.\n",
      "endraega.\n",
      "zered.\n",
      "elin.\n",
      "shi.\n",
      "jenleigh.\n",
      "sana.\n",
      "arleigh.\n",
      "malaia.\n",
      "noshubergihimie.\n",
      "trickennellennie.\n",
      "casube.\n",
      "geder.\n",
      "yarulyeh.\n",
      "yuma.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20): # genrate 20 names\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all \"...\" (3 dots)\n",
    "    while True:\n",
    "        # ------------\n",
    "        # forward pass:\n",
    "        # Embedding\n",
    "        emb = C[torch.tensor([context])] # (1,block_size, n_embd)      \n",
    "        embcat = emb.view(emb.shape[0], -1) # concat into (1, block_size * n_embd)\n",
    "        # Linear combination\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        # batch normalization\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        # non linear : activation\n",
    "        h = torch.tanh(hpreact) # (1, n_hidden)\n",
    "        # raw outputs\n",
    "        logits = h @ W2 + b2 # (1, vocab_size)\n",
    "        # ------------\n",
    "        # transforming outputs into probabilities with Softmax\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sampling 1 outcome from the multinomial distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        # add the indexe of the chosen proba into out:\n",
    "        out.append(ix)\n",
    "        if ix == 0:  # if the character is '.'(equivalent to EOS) end it, and generate the next word\n",
    "            break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # printing the gerated word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Younes Dahami](https://www.linkedin.com/in/dahami/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
